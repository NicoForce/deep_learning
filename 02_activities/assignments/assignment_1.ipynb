{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927ae8f4",
   "metadata": {},
   "source": [
    "# Assignment 1 - Building a Vision Model with Keras\n",
    "\n",
    "In this assignment, you will build a simple vision model using Keras. The goal is to classify images from the Fashion MNIST dataset, which contains images of clothing items.\n",
    "\n",
    "You will:\n",
    "1. Load and inspect the Fashion MNIST dataset.\n",
    "2. Run a simple baseline model to establish a performance benchmark.\n",
    "3. Build and evaluate a simple CNN model, choosing appropriate loss and metrics.\n",
    "4. Design and run controlled experiments on one hyperparameter (e.g., number of filters, kernel size, etc.) and one regularization technique (e.g., dropout, L2 regularization).\n",
    "5. Analyze the results and visualize the model's performance.\n",
    "\n",
    "# 1. Loading and Inspecting the Dataset\n",
    "\n",
    "Fashion MNIST is a dataset of grayscale images of clothing items, with 10 classes. Each image is 28x28 pixels, like the MNIST dataset of handwritten digits. Keras provides a convenient way to load this dataset. \n",
    "\n",
    "In this section, you should:\n",
    "\n",
    "- [ ] Inspect the shapes of the training and test sets to confirm their size and structure.\n",
    "- [ ] Convert the labels to one-hot encoded format if necessary. (There is a utility function in Keras for this.)\n",
    "- [ ] Visualize a few images from the dataset to understand what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Classes in the Fashion MNIST dataset\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c89fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the shapes of the datasets\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_classes = len(class_names)\n",
    "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
    "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
    "\n",
    "print(y_test_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13e100db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Verify the data looks as expected\n",
    "\n",
    "# Creating a 3x3 grid plot\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title(f\"Label: {class_names[y_train[i]]}\")\n",
    "\n",
    "    # Removing axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989f7dd0",
   "metadata": {},
   "source": [
    "Reflection: Does the data look as expected? How is the quality of the images? Are there any issues with the dataset that you notice?\n",
    "\n",
    "**There are weird details in the data, such as high heels being categorized as sandals, very little difference between pullovers and tshirt, tshirts and tops being categorized together where images can be very different. As for the quality of the images, they are not exactly high resolution, but items can be distinguishable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8ad60",
   "metadata": {},
   "source": [
    "# 2. Baseline Model\n",
    "\n",
    "In this section, you will create a linear regression model as a baseline. This model will not use any convolutional layers, but it will help you understand the performance of a simple model on this dataset.\n",
    "You should:\n",
    "- [ ] Create a simple linear regression model using Keras.\n",
    "- [ ] Compile the model with an appropriate loss function and optimizer.\n",
    "- [ ] Train the model on the training set and evaluate it on the test set.\n",
    "\n",
    "A linear regression model can be created using the `Sequential` API in Keras. Using a single `Dense` layer with no activation function is equivalent to a simple linear regression model. Make sure that the number of units in the output layer matches the number of classes in the dataset.\n",
    "\n",
    "Note that for this step, we will need to use `Flatten` to convert the 2D images into 1D vectors before passing them to the model. Put a `Flatten()` layer as the first layer in your model so that the 2D image data can be flattened into 1D vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8563a7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-07-06 16:08:34.521285: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NOT_INITIALIZED: initialization error\n",
      "2025-07-06 16:08:34.521343: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:135] retrieving CUDA diagnostic information for host: aurora\n",
      "2025-07-06 16:08:34.521351: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:142] hostname: aurora\n",
      "2025-07-06 16:08:34.521573: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:166] libcuda reported version is: 575.64.0\n",
      "2025-07-06 16:08:34.521605: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] kernel reported version is: 575.64.0\n",
      "2025-07-06 16:08:34.521614: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:249] kernel version seems to match DSO: 575.64.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 16:08:35.019771: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150528000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1464/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.1685 - loss: 10.3039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 16:08:36.751468: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 37632000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1684 - loss: 10.2984 - val_accuracy: 0.1774 - val_loss: 9.9114\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 855us/step - accuracy: 0.1736 - loss: 10.0694 - val_accuracy: 0.1848 - val_loss: 8.9295\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.1904 - loss: 9.7696 - val_accuracy: 0.2268 - val_loss: 8.4768\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.2356 - loss: 7.9974 - val_accuracy: 0.2591 - val_loss: 8.1235\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.2472 - loss: 9.2965 - val_accuracy: 0.2593 - val_loss: 10.1275\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.2466 - loss: 10.1796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.085091590881348, 0.2508000135421753]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# Create a simple linear regression model\n",
    "model = Sequential()\n",
    "\n",
    "# You can use `model.add(<layer>)` to add layers to the model\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# Compile the model using `model.compile()`\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with `model.fit()`\n",
    "model.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model with `model.evaluate()`\n",
    "model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07e9f7",
   "metadata": {},
   "source": [
    "Reflection: What is the performance of the baseline model? How does it compare to what you expected? Why do you think the performance is at this level?\n",
    "\n",
    "**Performance is at 24.66%, I didn't expect much of it, but around 25% seems kind of low, I probably expected around 45-55% accuracy. I believe the performance is low because it requires more iterations, or simply because a linear regression model is not fit for this kind of problem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa107b59",
   "metadata": {},
   "source": [
    "# 3. Building and Evaluating a Simple CNN Model\n",
    "\n",
    "In this section, you will build a simple Convolutional Neural Network (CNN) model using Keras. A convolutional neural network is a type of deep learning model that is particularly effective for image classification tasks. Unlike the basic neural networks we have built in the labs, CNNs can accept images as input without needing to flatten them into vectors.\n",
    "\n",
    "You should:\n",
    "- [ ] Build a simple CNN model with at least one convolutional layer (to learn spatial hierarchies in images) and one fully connected layer (to make predictions).\n",
    "- [ ] Compile the model with an appropriate loss function and metrics for a multi-class classification problem.\n",
    "- [ ] Train the model on the training set and evaluate it on the test set.\n",
    "\n",
    "Convolutional layers are designed to accept inputs with three dimensions: height, width and channels (e.g., RGB for color images). For grayscale images like those in Fashion MNIST, the input shape will be (28, 28, 1).\n",
    "\n",
    "When you progress from the convolutional layers to the fully connected layers, you will need to flatten the output of the convolutional layers. This can be done using the `Flatten` layer in Keras, which doesn't require any parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3513cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 16:22:28.362756: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 150528000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1491/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.5463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 16:22:34.112671: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 37632000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.5455 - val_accuracy: 0.8838 - val_loss: 0.3335\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.2994 - val_accuracy: 0.8882 - val_loss: 0.3087\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9097 - loss: 0.2536 - val_accuracy: 0.8953 - val_loss: 0.2925\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9207 - loss: 0.2239 - val_accuracy: 0.8943 - val_loss: 0.3025\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.2012 - val_accuracy: 0.9012 - val_loss: 0.2848\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9007 - loss: 0.2944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2925844192504883, 0.8964999914169312]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Conv2D\n",
    "\n",
    "# Reshape the data to include the channel dimension\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Create a simple CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe379c",
   "metadata": {},
   "source": [
    "Reflection: Did the CNN model perform better than the baseline model? If so, by how much? What do you think contributed to this improvement?\n",
    "\n",
    "**The CNN model at 90% accuracy performed way better than the baseline model, which was at less than 25%, I'd say the bigger improvement is using a model that's specifically designed for classifying images.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e2463",
   "metadata": {},
   "source": [
    "# 3. Designing and Running Controlled Experiments\n",
    "\n",
    "In this section, you will design and run controlled experiments to improve the model's performance. You will focus on one hyperparameter and one regularization technique.\n",
    "You should:\n",
    "- [ ] Choose one hyperparameter to experiment with (e.g., number of filters, kernel size, number of layers, etc.) and one regularization technique (e.g., dropout, L2 regularization). For your hyperparameter, you should choose at least three different values to test (but there is no upper limit). For your regularization technique, simply test the presence or absence of the technique.\n",
    "- [ ] Run experiments by modifying the model architecture or hyperparameters, and evaluate the performance of each model on the test set.\n",
    "- [ ] Record the results of your experiments, including the test accuracy and any other relevant metrics.\n",
    "- [ ] Visualize the results of your experiments using plots or tables to compare the performance of different models.\n",
    "\n",
    "The best way to run your experiments is to create a `for` loop that iterates over a range of values for the hyperparameter you are testing. For example, if you are testing different numbers of filters, you can create a loop that runs the model with 32, 64, and 128 filters. Within the loop, you can compile and train the model, then evaluate it on the test set. After each iteration, you can store the results in a list or a dictionary for later analysis.\n",
    "\n",
    "Note: It's critical that you re-initialize the model (by creating a new instance of the model) before each experiment. If you don't, the model will retain the weights from the previous experiment, which can lead to misleading results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6f46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.5457 - val_accuracy: 0.8819 - val_loss: 0.3320\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8962 - loss: 0.2900 - val_accuracy: 0.8948 - val_loss: 0.2936\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.2470 - val_accuracy: 0.8904 - val_loss: 0.3026\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.2146 - val_accuracy: 0.8937 - val_loss: 0.2954\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.1963 - val_accuracy: 0.8997 - val_loss: 0.2884\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.3026\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8120 - loss: 0.5267 - val_accuracy: 0.8768 - val_loss: 0.3433\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8959 - loss: 0.2860 - val_accuracy: 0.8887 - val_loss: 0.3083\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2364 - val_accuracy: 0.8930 - val_loss: 0.2977\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.2014 - val_accuracy: 0.8934 - val_loss: 0.3042\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9363 - loss: 0.1766 - val_accuracy: 0.8986 - val_loss: 0.2954\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.3115\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.8189 - loss: 0.5150 - val_accuracy: 0.8867 - val_loss: 0.3183\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9052 - loss: 0.2707 - val_accuracy: 0.8960 - val_loss: 0.2958\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9215 - loss: 0.2168 - val_accuracy: 0.8984 - val_loss: 0.2882\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9344 - loss: 0.1834 - val_accuracy: 0.8980 - val_loss: 0.2924\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.9434 - loss: 0.1574 - val_accuracy: 0.9026 - val_loss: 0.3020\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.3131\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.8217 - loss: 0.5081 - val_accuracy: 0.8772 - val_loss: 0.3441\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.9002 - loss: 0.2751 - val_accuracy: 0.8897 - val_loss: 0.3132\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 20ms/step - accuracy: 0.9225 - loss: 0.2156 - val_accuracy: 0.8925 - val_loss: 0.3105\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.9380 - loss: 0.1732 - val_accuracy: 0.9002 - val_loss: 0.2968\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - accuracy: 0.9481 - loss: 0.1444 - val_accuracy: 0.9007 - val_loss: 0.2999\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8990 - loss: 0.3260\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 43ms/step - accuracy: 0.8253 - loss: 0.5040 - val_accuracy: 0.8852 - val_loss: 0.3171\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 42ms/step - accuracy: 0.9001 - loss: 0.2733 - val_accuracy: 0.8976 - val_loss: 0.2900\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 43ms/step - accuracy: 0.9254 - loss: 0.2083 - val_accuracy: 0.8972 - val_loss: 0.3003\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 43ms/step - accuracy: 0.9382 - loss: 0.1693 - val_accuracy: 0.8953 - val_loss: 0.3026\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 43ms/step - accuracy: 0.9499 - loss: 0.1368 - val_accuracy: 0.8955 - val_loss: 0.3303\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8981 - loss: 0.3432\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8065 - loss: 0.5553 - val_accuracy: 0.8853 - val_loss: 0.3310\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.2861 - val_accuracy: 0.8927 - val_loss: 0.3021\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9104 - loss: 0.2522 - val_accuracy: 0.9002 - val_loss: 0.2875\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9216 - loss: 0.2141 - val_accuracy: 0.9005 - val_loss: 0.2867\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9305 - loss: 0.1947 - val_accuracy: 0.8957 - val_loss: 0.3063\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8891 - loss: 0.3150\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8003 - loss: 0.5657 - val_accuracy: 0.8808 - val_loss: 0.3370\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.3138 - val_accuracy: 0.8787 - val_loss: 0.3382\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2664 - val_accuracy: 0.8893 - val_loss: 0.3118\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2377 - val_accuracy: 0.8968 - val_loss: 0.2909\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.2151 - val_accuracy: 0.9032 - val_loss: 0.2811\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.2987\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7985 - loss: 0.5764 - val_accuracy: 0.8620 - val_loss: 0.3820\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8840 - loss: 0.3240 - val_accuracy: 0.8821 - val_loss: 0.3156\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8975 - loss: 0.2858 - val_accuracy: 0.8873 - val_loss: 0.3182\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2494 - val_accuracy: 0.8905 - val_loss: 0.2987\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9213 - loss: 0.2215 - val_accuracy: 0.8948 - val_loss: 0.2958\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8909 - loss: 0.3174\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.6042 - val_accuracy: 0.8632 - val_loss: 0.3846\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8772 - loss: 0.3421 - val_accuracy: 0.8844 - val_loss: 0.3230\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.3002 - val_accuracy: 0.8801 - val_loss: 0.3340\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9008 - loss: 0.2719 - val_accuracy: 0.8888 - val_loss: 0.3126\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 0.2449 - val_accuracy: 0.8928 - val_loss: 0.3059\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8883 - loss: 0.3275\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.6240 - val_accuracy: 0.8630 - val_loss: 0.3880\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8687 - loss: 0.3622 - val_accuracy: 0.8783 - val_loss: 0.3482\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8831 - loss: 0.3201 - val_accuracy: 0.8830 - val_loss: 0.3306\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8988 - loss: 0.2790 - val_accuracy: 0.8792 - val_loss: 0.3346\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.2642 - val_accuracy: 0.8823 - val_loss: 0.3290\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8731 - loss: 0.3594\n",
      "[{'filter_size_32': 0.30088070034980774}, {'filter_size_64': 0.30552908778190613}, {'filter_size_128': 0.3077860474586487}, {'filter_size_256': 0.3131532371044159}, {'filter_size_512': 0.3348771333694458}, {'filter_size_(3, 3)': 0.31529107689857483}, {'filter_size_(5, 5)': 0.2962338328361511}, {'filter_size_(7, 7)': 0.31640124320983887}, {'filter_size_(9, 9)': 0.3256962299346924}, {'filter_size_(11, 11)': 0.3549685776233673}]\n",
      "[{'filter_size_32': 0.8932999968528748}, {'filter_size_64': 0.8986999988555908}, {'filter_size_128': 0.9006999731063843}, {'filter_size_256': 0.8973000049591064}, {'filter_size_512': 0.8968999981880188}, {'filter_size_(3, 3)': 0.8876000046730042}, {'filter_size_(5, 5)': 0.8982999920845032}, {'filter_size_(7, 7)': 0.8899000287055969}, {'filter_size_(9, 9)': 0.8866000175476074}, {'filter_size_(11, 11)': 0.8758999705314636}]\n"
     ]
    }
   ],
   "source": [
    "# A. Test Hyperparameters\n",
    "loss_results = []\n",
    "acc_results = []\n",
    "\n",
    "# 1. Testing filter size\n",
    "filter_sizes = [32, 64, 128, 256, 512]\n",
    "for i in filter_sizes:\n",
    "    # Create a simple CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(i, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test_cat)\n",
    "    loss_results.append({f'filter_size_{i}': test_loss})\n",
    "    acc_results.append({f'filter_size_{i}': test_accuracy})\n",
    "\n",
    "\n",
    "# 2. Testing kernel size\n",
    "kernel_sizes = [(3, 3), (5, 5), (7, 7), (9, 9), (11, 11)]\n",
    "for i in kernel_sizes:\n",
    "    # Create a simple CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=i, activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test_cat)\n",
    "    loss_results.append({f'kernel_size{i}': test_loss})\n",
    "    acc_results.append({f'kernel_size{i}': test_accuracy})\n",
    "\n",
    "print(loss_results)\n",
    "print(acc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf2d529f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.8110 - loss: 0.5301 - val_accuracy: 0.8852 - val_loss: 0.3162\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9029 - loss: 0.2696 - val_accuracy: 0.8995 - val_loss: 0.2693\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9263 - loss: 0.2040 - val_accuracy: 0.9120 - val_loss: 0.2516\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9442 - loss: 0.1564 - val_accuracy: 0.9047 - val_loss: 0.2800\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9579 - loss: 0.1193 - val_accuracy: 0.9155 - val_loss: 0.2641\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2739\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.7890 - loss: 0.6028 - val_accuracy: 0.8736 - val_loss: 0.3469\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.8831 - loss: 0.3299 - val_accuracy: 0.8964 - val_loss: 0.2892\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.8977 - loss: 0.2799 - val_accuracy: 0.8991 - val_loss: 0.2784\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.9062 - loss: 0.2609 - val_accuracy: 0.9051 - val_loss: 0.2605\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 15ms/step - accuracy: 0.9149 - loss: 0.2326 - val_accuracy: 0.9072 - val_loss: 0.2482\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2635\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7473 - loss: 0.7172 - val_accuracy: 0.8637 - val_loss: 0.3842\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.3668 - val_accuracy: 0.8766 - val_loss: 0.3339\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8869 - loss: 0.3120 - val_accuracy: 0.8901 - val_loss: 0.3043\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8993 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 0.2953\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9059 - loss: 0.2564 - val_accuracy: 0.8985 - val_loss: 0.2843\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8918 - loss: 0.3015\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6397 - loss: 0.9906 - val_accuracy: 0.8296 - val_loss: 0.4523\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.7976 - loss: 0.5360 - val_accuracy: 0.8699 - val_loss: 0.3644\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8303 - loss: 0.4656 - val_accuracy: 0.8798 - val_loss: 0.3298\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8455 - loss: 0.4209 - val_accuracy: 0.8832 - val_loss: 0.3140\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8594 - loss: 0.3907 - val_accuracy: 0.8916 - val_loss: 0.3031\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.3257\n",
      "[{'model_a': 0.26889586448669434}, {'model_b': 0.2599611282348633}, {'model_c': 0.29706236720085144}, {'model_d': 0.32146376371383667}]\n",
      "[{'model_a': 0.9139000177383423}, {'model_b': 0.9049999713897705}, {'model_c': 0.8913999795913696}, {'model_d': 0.8826000094413757}]\n"
     ]
    }
   ],
   "source": [
    "# 3. Adding more layers\n",
    "from keras.layers import Dropout, MaxPooling2D\n",
    "\n",
    "loss_results = []\n",
    "acc_results = []\n",
    "\n",
    "model_a = Sequential()\n",
    "model_a.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_a.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_a.add(Flatten())\n",
    "model_a.add(Dense(10, activation='softmax'))\n",
    "model_a.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_a.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "test_loss, test_accuracy = model_a.evaluate(X_test, y_test_cat)\n",
    "loss_results.append({f'model_a': test_loss})\n",
    "acc_results.append({f'model_a': test_accuracy})\n",
    "\n",
    "model_b = Sequential()\n",
    "model_b.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_b.add(Dropout(0.5))\n",
    "model_b.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_b.add(Dropout(0.5))\n",
    "model_b.add(Flatten())\n",
    "model_b.add(Dense(10, activation='softmax'))\n",
    "model_b.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_b.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "test_loss, test_accuracy = model_b.evaluate(X_test, y_test_cat)\n",
    "loss_results.append({f'model_b': test_loss})\n",
    "acc_results.append({f'model_b': test_accuracy})\n",
    "\n",
    "model_c = Sequential()\n",
    "model_c.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_c.add(MaxPooling2D((2, 2)))\n",
    "model_c.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_c.add(MaxPooling2D((2, 2)))\n",
    "model_c.add(Flatten())\n",
    "model_c.add(Dense(10, activation='softmax'))\n",
    "model_c.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_c.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "test_loss, test_accuracy = model_c.evaluate(X_test, y_test_cat)\n",
    "loss_results.append({f'model_c': test_loss})\n",
    "acc_results.append({f'model_c': test_accuracy})\n",
    "\n",
    "model_d = Sequential()\n",
    "model_d.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_d.add(MaxPooling2D((2, 2)))\n",
    "model_d.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_d.add(MaxPooling2D((2, 2)))\n",
    "model_d.add(Flatten())\n",
    "model_d.add(Dense(64, activation='relu'))\n",
    "model_d.add(Dropout(0.5))\n",
    "model_d.add(Dense(10, activation='softmax'))\n",
    "model_d.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_d.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "test_loss, test_accuracy = model_d.evaluate(X_test, y_test_cat)\n",
    "loss_results.append({f'model_d': test_loss})\n",
    "acc_results.append({f'model_d': test_accuracy})\n",
    "\n",
    "print(loss_results)\n",
    "print(acc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43ac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8014 - loss: 0.5589 - val_accuracy: 0.8782 - val_loss: 0.3323\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.3016 - val_accuracy: 0.8879 - val_loss: 0.3136\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9063 - loss: 0.2614 - val_accuracy: 0.8947 - val_loss: 0.2981\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.2387 - val_accuracy: 0.8974 - val_loss: 0.2985\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.2044 - val_accuracy: 0.8973 - val_loss: 0.3028\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8908 - loss: 0.3251\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.5562 - val_accuracy: 0.8711 - val_loss: 0.3574\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8916 - loss: 0.3034 - val_accuracy: 0.8884 - val_loss: 0.3136\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9050 - loss: 0.2655 - val_accuracy: 0.8936 - val_loss: 0.2921\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9152 - loss: 0.2344 - val_accuracy: 0.8992 - val_loss: 0.2904\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9220 - loss: 0.2135 - val_accuracy: 0.8946 - val_loss: 0.2995\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8916 - loss: 0.3131\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7997 - loss: 0.5739 - val_accuracy: 0.8777 - val_loss: 0.3380\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.3210 - val_accuracy: 0.8890 - val_loss: 0.3072\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8996 - loss: 0.2844 - val_accuracy: 0.8953 - val_loss: 0.2924\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.2607 - val_accuracy: 0.8998 - val_loss: 0.2865\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9100 - loss: 0.2451 - val_accuracy: 0.8993 - val_loss: 0.2838\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.3002\n",
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7805 - loss: 0.6185 - val_accuracy: 0.8754 - val_loss: 0.3543\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8645 - loss: 0.3718 - val_accuracy: 0.8852 - val_loss: 0.3193\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8807 - loss: 0.3351 - val_accuracy: 0.8856 - val_loss: 0.3151\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.3323 - val_accuracy: 0.8905 - val_loss: 0.3045\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.8876 - loss: 0.3098 - val_accuracy: 0.8922 - val_loss: 0.3006\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8919 - loss: 0.3171\n",
      "[{'filter_size_0': 0.32229429483413696}, {'filter_size_0.25': 0.30947145819664}, {'filter_size_0.5': 0.30065658688545227}, {'filter_size_0.75': 0.31667813658714294}]\n",
      "[{'filter_size_0': 0.8899000287055969}, {'filter_size_0.25': 0.8894000053405762}, {'filter_size_0.5': 0.8921999931335449}, {'filter_size_0.75': 0.8870999813079834}]\n"
     ]
    }
   ],
   "source": [
    "# B. Test presence or absence of regularization\n",
    "loss_results = []\n",
    "acc_results = []\n",
    "\n",
    "# 1. Testing dropout\n",
    "dropout = [0, 0.25, 0.5, 0.75]\n",
    "for i in dropout:\n",
    "    # Create a simple CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(Dropout(i))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test_cat)\n",
    "    loss_results.append({f'dropout{i}': test_loss})\n",
    "    acc_results.append({f'dropout{i}': test_accuracy})\n",
    "\n",
    "print(loss_results)\n",
    "print(acc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb426f26",
   "metadata": {},
   "source": [
    "Reflection: Report on the performance of the models you tested. Did any of the changes you made improve the model's performance? If so, which ones? What do you think contributed to these improvements? Finally, what combination of hyperparameters and regularization techniques yielded the best performance?\n",
    "\n",
    "**From my experiments, a few changes made the model perform better, such as having an extra conv2d layer, no regularization, a filter_size of 128 and a kernel size of 5. I didn't exactly combine changes together, but I'm gonna test a combination of the best params in the final model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c43a3d",
   "metadata": {},
   "source": [
    "# 5. Training Final Model and Evaluation\n",
    "\n",
    "In this section, you will train the final model using the best hyperparameters and regularization techniques you found in the previous section. You should:\n",
    "- [ ] Compile the final model with the best hyperparameters and regularization techniques.\n",
    "- [ ] Train the final model on the training set and evaluate it on the test set.\n",
    "- [ ] Report the final model's performance on the test set, including accuracy and any other relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31f926d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/miniconda3/envs/dsi_participant/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 76ms/step - accuracy: 0.8012 - loss: 0.5460 - val_accuracy: 0.8836 - val_loss: 0.3164\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 79ms/step - accuracy: 0.8918 - loss: 0.2972 - val_accuracy: 0.8893 - val_loss: 0.3044\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 80ms/step - accuracy: 0.9150 - loss: 0.2317 - val_accuracy: 0.9065 - val_loss: 0.2697\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 81ms/step - accuracy: 0.9307 - loss: 0.1875 - val_accuracy: 0.9066 - val_loss: 0.2672\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 81ms/step - accuracy: 0.9454 - loss: 0.1505 - val_accuracy: 0.9035 - val_loss: 0.2728\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.8961 - loss: 0.3187\n",
      "0.30513516068458557 0.8978999853134155\n"
     ]
    }
   ],
   "source": [
    "# 2 layers of cond2d, filter_size is 128 (both layers), kernel size of 5 (both layers), no regularization\n",
    "model_final = Sequential()\n",
    "model_final.add(Conv2D(128, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_final.add(Conv2D(128, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_final.add(Flatten())\n",
    "model_final.add(Dense(10, activation='softmax'))\n",
    "model_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_final.fit(X_train, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
    "test_loss, test_accuracy = model_final.evaluate(X_test, y_test_cat)\n",
    "print(test_loss, test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f8ebc",
   "metadata": {},
   "source": [
    "Reflection: How does the final model's performance compare to the baseline and the CNN model? What do you think contributed to the final model's performance? If you had time, what other experiments would you run to further improve the model's performance?\n",
    "\n",
    "**My best model combined different hyperparameter tunning that separately improved the model performance even by a little; however, in combination, they didn't improve performance that much, performance is basically the same as the initial CNN model, but definitely way better than the baseline. If I had more time, I would combine the tunning of multiple hyperparams in combination, instead of just testing them separately, although I might need better hardware or learn how to get tensorflow to use my nvidia gpu to perform faster.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db8512",
   "metadata": {},
   "source": [
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `23:59 PM - 06/07/2025`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb)\n",
    "    * The Lab 1 notebook (labs/lab_1.ipynb)\n",
    "    * The Lab 2 notebook (labs/lab_2.ipynb)\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/deep_learning/pull/<pr_id>`\n",
    "* Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-6-ml-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
